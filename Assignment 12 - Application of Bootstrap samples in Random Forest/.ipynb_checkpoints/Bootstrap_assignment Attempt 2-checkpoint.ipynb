{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sNKZq4XrXQh"
   },
   "source": [
    "# <font color='red'><b>Bootstrap assignment</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAHap1Z3FZC-"
   },
   "source": [
    "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
    "\n",
    "Every Grader function has to return True.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuxBq_bvrwh2"
   },
   "source": [
    "<font color='blue'> <b>Importing packages</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6ag91ijrQOs"
   },
   "outputs": [],
   "source": [
    "import numpy as np # importing numpy for numerical computation\n",
    "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
    "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcHOsONTt1K_"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pc1htEFYuLRj",
    "outputId": "f5b60712-98b3-4cdc-b629-3546c1e3859c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEa_HqRZloH4"
   },
   "source": [
    "## <font color='red'><b>Task 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQ5q8IxHNRk3"
   },
   "source": [
    "<font color='red'> <b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJCFCaOzl7Mr"
   },
   "source": [
    "*  <font color='blue'><b>Creating samples</b></font><br>\n",
    "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
    "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
    "    \n",
    "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
    "* <font color='blue'><b> Create 30 samples </b></font>\n",
    "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
    "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
    "Make sure each sample will have atleast 3 feautres/columns/attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUqFEBSvNjCa"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uqi9AhCYNq3Z"
   },
   "source": [
    "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lLBnZHXOFln"
   },
   "source": [
    "*  Build a regression trees on each of 30 samples.\n",
    "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
    "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kls23JLnSN23"
   },
   "source": [
    "<font color='red'> <b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rz2GchkGSWnh"
   },
   "source": [
    "*  <font color='blue'><b>Calculating the OOB score </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGHkVV2kSibm"
   },
   "source": [
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
    "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK860ocxTyoz"
   },
   "source": [
    "# <font color='red'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dme-N6TUCrY"
   },
   "source": [
    "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
    "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
    "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
    "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
    "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
    "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6UcH1x9Uwrj"
   },
   "source": [
    "# <font color='red'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOC_AgsLU7OH"
   },
   "source": [
    "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYs5jSFdVILe"
   },
   "source": [
    "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
    "Predict the house price for this point as mentioned in the step 2 of Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6gxZEsFWm-8"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2fHTdS_zpgG"
   },
   "source": [
    "# <font color='blue'> <b>Task - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0yGBuryOwHz"
   },
   "source": [
    "<font color='blue'><b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJXX8vf3z073"
   },
   "source": [
    "*  <font color='blue'> <b>Creating samples</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSVaWG1F4uCZ"
   },
   "source": [
    "<font color='Orange'><b>Algorithm</b></font>\n",
    "\n",
    "![alt text](https://i.imgur.com/BTVYXQ1.jpg/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_oWoN97BhDY"
   },
   "source": [
    "*  <font color='blue'><b> Write code for generating samples</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ph_6D2SDzz7F"
   },
   "outputs": [],
   "source": [
    "# '''In this function, we will write code for generating 30 samples '''\n",
    "    # you can use random.choice to generate random indices without replacement\n",
    "    # Please have a look at this link https://docs.scipy.org/doc/numpy-1.16.0/reference/generated/numpy.random.choice.html for more details\n",
    "    # Please follow above pseudo code for generating samples \n",
    "    \n",
    "\n",
    "    # return sampled_input_data , sampled_target_data,selected_rows,selected_columns\n",
    "    #note please return as lists\n",
    "\n",
    "def generating_samples(input_data, target_data):\n",
    "    \n",
    "    Selecting_rows = np.random.choice(506 ,303 ,replace=False)   \n",
    "    Selecting_columns = np.random.choice([0,1,2,3,4,5,6,7,8,9,10,11,12], np.random.choice([3,4,5,6,7,8,9,10,11,12,13]) )\n",
    "    sample_data = input_data[ Selecting_rows[:,None] , Selecting_columns ]\n",
    "    target_of_sample_data = target_data[Selecting_rows]\n",
    "    \n",
    "    #Replicating data\n",
    "    Replacing_rows = np.random.choice(303, 203,replace=False)\n",
    "    Replicated_sample_data = sample_data[Replacing_rows]\n",
    "    target_of_Replicated_sample_data = target_of_sample_data[Replacing_rows]\n",
    "    \n",
    "    #Concatenation\n",
    "    final_sample_data = np.vstack((sample_data,Replicated_sample_data))\n",
    "    final_target_data = np.vstack((target_of_sample_data.reshape(-1,1),target_of_Replicated_sample_data.reshape(-1,1)))\n",
    "    \n",
    "    return final_sample_data,final_target_data,Selecting_rows,Selecting_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MivEQFlm7iOg"
   },
   "source": [
    "<font color='cyan'> <b> Grader function - 1 </b> </fongt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVvuhNzm7uld"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_samples(a,b,c,d):\n",
    "    length = (len(a)==506  and len(b)==506)\n",
    "    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
    "    rows_length = (len(c)==303)\n",
    "    column_length= (len(d)>=3)\n",
    "    assert(length and sampled and rows_length and column_length)\n",
    "    return True\n",
    "a,b,c,d = generating_samples(x, y)\n",
    "grader_samples(a,b,c,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4LSsmn4Jn2_"
   },
   "source": [
    "*  <font color='blue'> <b>Create 30 samples </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ec7MN6sL2BZ"
   },
   "source": [
    "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXlKWjCcBvTk"
   },
   "outputs": [],
   "source": [
    "# Use generating_samples function to create 30 samples \n",
    "# store these created samples in a list\n",
    "list_input_data =[]\n",
    "list_output_data =[]\n",
    "list_selected_row= []\n",
    "list_selected_columns=[]\n",
    "\n",
    "\n",
    "for i in range(0,30):\n",
    "    a,b,c,d = generating_samples(x,y)\n",
    "    list_input_data.append(a)\n",
    "    list_output_data.append(b)\n",
    "    list_selected_row.append(c)\n",
    "    list_selected_columns.append(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXUz9VFiMQkh"
   },
   "source": [
    "<font color='cyan'> <b>Grader function - 2 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCvIq8NuMWOC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_30(a):\n",
    "    assert(len(a)==30 and len(a[0])==506)\n",
    "    return True\n",
    "grader_30(list_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Pv-mkZkO6dh"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whaHCPB0O8qF"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBy4zXSWPtU8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for building tree</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xvH06HPQBdP"
   },
   "source": [
    "![alt text](https://i.imgur.com/pcXfSmp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRwPO_uHQjul"
   },
   "source": [
    "*  <font color='blue'><b> Write code for building regression trees</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWQp6tRwMthq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor(), DecisionTreeRegressor()]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "list_of_all_models = []\n",
    "\n",
    "for i in range(len(list_input_data)):\n",
    "    dt = DecisionTreeRegressor(max_depth = None)\n",
    "    \n",
    "    trained_dt = dt.fit(list_input_data[i],list_output_data[i])\n",
    "    \n",
    "    list_of_all_models.append(trained_dt)\n",
    "\n",
    "print(list_of_all_models)    #storing all decision trees for each set of input and output sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21j8BKfAQ1U8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Q0mTBD2RBx_"
   },
   "source": [
    "![alt text](https://i.imgur.com/sPEE618.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6e-UamlHRjPy"
   },
   "source": [
    "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnIMT7_oR312"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWhcvMRWRA9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.039582509881422916\n"
     ]
    }
   ],
   "source": [
    "array_of_Y = []\n",
    "\n",
    "for k in range(len(list_of_all_models)):\n",
    "\n",
    "    y_predicted = list_of_all_models[k].predict( x[:,list_selected_columns[k]]  )\n",
    " \n",
    "    array_of_Y.append(y_predicted)\n",
    "\n",
    "array_of_Y = np.array(array_of_Y)   #array of predicted Y all data points from x\n",
    "\n",
    "predicted_y = []\n",
    "\n",
    "for j in range(506):\n",
    "    \n",
    "    sorted_array_of_Y = np.sort(array_of_Y[:,j])\n",
    "    \n",
    "    median =  np.median(sorted_array_of_Y)\n",
    "    \n",
    "    predicted_y.append(median)   #median of prediction of each data point from all the 30 sets \n",
    "\n",
    "MSE = mean_squared_error(y, predicted_y )\n",
    "    \n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RuclPDMnSz8F"
   },
   "source": [
    "<font color='blue'><b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESb9FSIDTM5V"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HB-d6NMETbd9"
   },
   "source": [
    "![alt text](https://i.imgur.com/95S5Mtm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WW3GOcFzTqbt"
   },
   "source": [
    "Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zBqcS03pUYSZ"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 11, 13, 14, 17, 22, 24, 26], [5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 21, 23, 25, 26, 28, 29], [0, 1, 3, 4, 5, 6, 8, 9, 11, 13, 17, 21, 22, 23, 24, 26, 28], [4, 5, 6, 9, 11, 12, 14, 15, 17, 19, 24], [5, 8, 9, 16, 19, 21, 28]]\n"
     ]
    }
   ],
   "source": [
    "final_model_list = []    #for ith data point not in which samples/models\n",
    "\n",
    "for i in range(len(x)):\n",
    "    temp = []\n",
    "    for j in range(len(list_selected_row)):\n",
    "        if (i not in list_selected_row[j]):  #for each data point , storing the models for which this data point was not considered\n",
    "            temp.append(j)\n",
    "    final_model_list.append(temp)       \n",
    "    \n",
    "print(final_model_list[:5])   #length of 506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fog_6DNdS-h_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.96931710673051\n"
     ]
    }
   ],
   "source": [
    "#array_of_Y \n",
    "\n",
    "predicted_y = []\n",
    "\n",
    "for j in range(array_of_Y.shape[1]):\n",
    "\n",
    "   \n",
    "    sorted_array_of_Y = np.sort(array_of_Y[final_model_list[j],j])  #from array of all predictions ,choose only the models where ith point was not used (list in previous block)\n",
    "\n",
    "    median = np.median(sorted_array_of_Y)\n",
    "    \n",
    "    predicted_y.append(median)\n",
    "\n",
    "    \n",
    "OOB = mean_squared_error(y , predicted_y )\n",
    "    \n",
    "print(OOB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbuiwX3OUjUI"
   },
   "source": [
    "# <font color='blue'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ceW5-D88Uswi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 MSE Scores : \n",
      " [0.07703063241106725, 0.18720928853754942, 0.2419960474308301, 0.09516916996047439, 0.09120772588442816, 0.11063848338436015, 0.0395009881422925, 0.05561264822134389, 0.12635869565217392, 0.04510753767292489, 0.029150197628458527, 0.04700716403162053, 0.06384387351778661, 0.3925351310352865, 0.009240207234540597, 0.10354592116820392, 0.06150252525252522, 0.04281620553359686, 0.14819664031620558, 0.05352041126512326, 0.06568675889328068, 0.01657608695652172, 0.19062757118657733, 0.03340909090909095, 0.07006916996047435, 0.011002964426877478, 0.09020850351339488, 0.04695369512307116, 0.05483973567193676, 0.24840415019762857, 0.056849061264822136, 0.025879446640316214, 0.12128318124749328, 0.18546566205533577, 0.06975516029863857]\n",
      "\n",
      "35 OOB Scores : \n",
      " [14.53287453337725, 15.017660928831349, 13.436488526570047, 14.107198686622214, 16.01733341809545, 12.601590858187995, 14.549772727272726, 10.7008998270751, 13.38334761883424, 15.176447724582784, 14.145968379446641, 15.950983750548968, 11.490838842672263, 13.140575440767572, 12.719290854307983, 12.930442509737203, 12.25596643256698, 13.8651185770751, 11.290968379446639, 13.484062796031196, 14.56314723320158, 11.327782855731224, 14.295874157912767, 15.249782632166097, 11.303486632630653, 14.666441178085197, 12.20390640452914, 13.143070423765382, 15.10691854001976, 13.172223274936549, 15.174440009826768, 15.2400395256917, 13.202148960835446, 14.20138666007905, 12.230044045129581]\n"
     ]
    }
   ],
   "source": [
    "MSE_35 = []      #runinng above code for 35 times and storing MSE of each run\n",
    "OOB_35 = []      #runinng above code for 35 times and storing OOB of each run\n",
    "\n",
    "for z in range(35):\n",
    "    \n",
    "    def generating_samples(input_data, target_data):\n",
    "    \n",
    "        Selecting_rows = np.random.choice(506 ,303 ,replace=False)   \n",
    "        Selecting_columns = np.random.choice([0,1,2,3,4,5,6,7,8,9,10,11,12], np.random.choice([3,4,5,6,7,8,9,10,11,12,13]) , replace=False)\n",
    "        sample_data = input_data[ Selecting_rows[:,None] , Selecting_columns ]\n",
    "        target_of_sample_data = target_data[Selecting_rows]\n",
    "\n",
    "        #Replicating data\n",
    "        Replacing_rows = np.random.choice(303, 203)\n",
    "        Replicated_sample_data = sample_data[Replacing_rows]\n",
    "        target_of_Replicated_sample_data = target_of_sample_data[Replacing_rows]\n",
    "\n",
    "        #Concatenation\n",
    "        final_sample_data = np.vstack((sample_data,Replicated_sample_data))\n",
    "        final_target_data = np.vstack((target_of_sample_data.reshape(-1,1),target_of_Replicated_sample_data.reshape(-1,1)))\n",
    "\n",
    "        return final_sample_data,final_target_data,Selecting_rows,Selecting_columns\n",
    "\n",
    "    list_input_data =[]\n",
    "    list_output_data =[]\n",
    "    list_selected_row= []\n",
    "    list_selected_columns=[]\n",
    "\n",
    "    for i in range(0,30):\n",
    "        a,b,c,d = generating_samples(x,y)\n",
    "        list_input_data.append(a)\n",
    "        list_output_data.append(b)\n",
    "        list_selected_row.append(c)\n",
    "        list_selected_columns.append(d)\n",
    "        \n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "    list_of_all_models = []\n",
    "\n",
    "    for i in range(len(list_input_data)):\n",
    "        dt = DecisionTreeRegressor(max_depth = None)\n",
    "        trained_dt = dt.fit(list_input_data[i],list_output_data[i])\n",
    "        list_of_all_models.append(trained_dt)\n",
    "        \n",
    "    from sklearn.metrics import mean_squared_error\n",
    " \n",
    "    array_of_Y = []\n",
    "\n",
    "    for k in range(len(list_of_all_models)):\n",
    "\n",
    "        y_predicted = list_of_all_models[k].predict(x[:,list_selected_columns[k]])\n",
    "\n",
    "        array_of_Y.append(y_predicted)\n",
    "\n",
    "    array_of_Y = np.array(array_of_Y)\n",
    "\n",
    "    predicted_y = []\n",
    "\n",
    "    for j in range(array_of_Y.shape[1]):\n",
    "\n",
    "        sorted_array_of_Y = np.sort(array_of_Y[:,j])\n",
    "\n",
    "        median = np.median(sorted_array_of_Y)\n",
    "\n",
    "        predicted_y.append(median)\n",
    "\n",
    "\n",
    "    MSE_35.append(mean_squared_error(y , predicted_y ))\n",
    "    \n",
    "    predicted_y = []\n",
    "    \n",
    "    final_model_list = []    #for ith data point not in which samples/models\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        temp = []\n",
    "        for j in range(len(list_selected_row)):\n",
    "            if (i not in list_selected_row[j]):  #for each data point , storing the models for which this data point was not considered\n",
    "                temp.append(j)\n",
    "        final_model_list.append(temp)       \n",
    "\n",
    "    \n",
    "\n",
    "    for j in range(array_of_Y.shape[1]):\n",
    "\n",
    "        \n",
    "        sorted_array_of_Y = np.sort(array_of_Y[final_model_list[j],j])  #from array of all predictions ,choose only the models where ith point was not used\n",
    "\n",
    "        median = np.median(sorted_array_of_Y)\n",
    "\n",
    "        predicted_y.append(median)\n",
    "\n",
    "\n",
    "    OOB_35.append(mean_squared_error(y , predicted_y ))\n",
    "\n",
    "print(\"35 MSE Scores : \\n\" , MSE_35)\n",
    "print(\"\\n35 OOB Scores : \\n\" ,OOB_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI of MSE :  [0.068, 0.122]\n",
      "95% CI of OOB :  [13.124, 14.07]\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval using the python notebook on central limit theorem\n",
    "\n",
    "s_MSE_std = np.std(np.array(MSE_35))\n",
    "x_MSE_mean = np.round(np.mean(np.array(MSE_35)), 3)\n",
    "size_MSE = len(MSE_35)\n",
    "\n",
    "left_limit  = np.round(x_MSE_mean - 2*(s_MSE_std/np.sqrt(size_MSE)), 3)\n",
    "right_limit  = np.round(x_MSE_mean + 2*(s_MSE_std/np.sqrt(size_MSE)), 3)\n",
    "\n",
    "print(\"95% CI of MSE : \" , [left_limit,right_limit])\n",
    "\n",
    "\n",
    "s_OOB_std = np.std(np.array(OOB_35))\n",
    "x_OOB_mean = np.round(np.mean(np.array(OOB_35)), 3)\n",
    "size_OOB = len(OOB_35)\n",
    "\n",
    "left_limit  = np.round(x_OOB_mean - 2*(s_OOB_std/np.sqrt(size_OOB)), 3)\n",
    "right_limit  = np.round(x_OOB_mean + 2*(s_OOB_std/np.sqrt(size_OOB)), 3)\n",
    "\n",
    "print(\"95% CI of OOB : \" , [left_limit,right_limit])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKTnJdiBVS_e"
   },
   "source": [
    "# <font color='blue'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXxrvZqHV1Fr"
   },
   "source": [
    "<font color='orange'><b>Flowchart for Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyjwEJ62V6a6"
   },
   "source": [
    "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0emSwLL7VurD"
   },
   "source": [
    "![alt text](https://i.imgur.com/Y5cNhQk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29hjwKlWWDfo"
   },
   "source": [
    "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_pUlSD-VYD1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price of the house for given Xq:  [18.5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generating_samples(input_data, target_data):\n",
    "\n",
    "    Selecting_rows = np.random.choice(506 ,303 ,replace=False)   \n",
    "    Selecting_columns = np.random.choice([0,1,2,3,4,5,6,7,8,9,10,11,12], np.random.choice([3,4,5,6,7,8,9,10,11,12,13]) , replace=False)\n",
    "    sample_data = input_data[ Selecting_rows[:,None] , Selecting_columns ]\n",
    "    target_of_sample_data = target_data[Selecting_rows]\n",
    "\n",
    "    #Replicating data\n",
    "    Replacing_rows = np.random.choice(303, 203)\n",
    "    Replicated_sample_data = sample_data[Replacing_rows]\n",
    "    target_of_Replicated_sample_data = target_of_sample_data[Replacing_rows]\n",
    "\n",
    "    #Concatenation\n",
    "    final_sample_data = np.vstack((sample_data,Replicated_sample_data))\n",
    "    final_target_data = np.vstack((target_of_sample_data.reshape(-1,1),target_of_Replicated_sample_data.reshape(-1,1)))\n",
    "\n",
    "    return final_sample_data,final_target_data,Selecting_rows,Selecting_columns\n",
    "\n",
    "list_input_data =[]\n",
    "list_output_data =[]\n",
    "list_selected_row= []\n",
    "list_selected_columns=[]\n",
    "\n",
    "for i in range(0,30):\n",
    "    a,b,c,d = generating_samples(x,y)\n",
    "    list_input_data.append(a)\n",
    "    list_output_data.append(b)\n",
    "    list_selected_row.append(c)\n",
    "    list_selected_columns.append(d)\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "list_of_all_models = []\n",
    "\n",
    "for i in range(len(list_input_data)):\n",
    "    dt = DecisionTreeRegressor(max_depth = None)\n",
    "    trained_dt = dt.fit(list_input_data[i],list_output_data[i])\n",
    "    list_of_all_models.append(trained_dt)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "array_of_Y = []\n",
    "\n",
    "for k in range(len(list_of_all_models)):\n",
    "    \n",
    "    xq = [[0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60],]\n",
    "    \n",
    "    xq = np.array(xq)\n",
    "    \n",
    "    y_predicted = list_of_all_models[k].predict(  xq[:,list_selected_columns[k]] )\n",
    "\n",
    "    array_of_Y.append(y_predicted)\n",
    "\n",
    "array_of_Y = np.array(array_of_Y)\n",
    "\n",
    "predicted_y = []\n",
    "\n",
    "for j in range(array_of_Y.shape[1]):\n",
    "\n",
    "    sorted_array_of_Y = np.sort(array_of_Y[:,j])\n",
    "    \n",
    "    median = np.median(sorted_array_of_Y)\n",
    "\n",
    "    predicted_y.append(median)\n",
    "\n",
    "print(\"Price of the house for given Xq: \" , predicted_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJHTGEZgWJjR"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IOdUi-0xWOJ9"
   },
   "source": [
    "<font color='red'><b>Write observations for task 1, task 2, task 3 indetail</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIcax45hWKT-"
   },
   "source": [
    "Task 1 Observations :\n",
    "\n",
    "    MSE is 0.039582509881422916\n",
    "\n",
    "    OOB is 16.96931710673051\n",
    "\n",
    "Task 2 Observations : \n",
    "\n",
    "    35 MSE Scores : \n",
    "     [0.07703063241106725, 0.18720928853754942, 0.2419960474308301, 0.09516916996047439, 0.09120772588442816, 0.11063848338436015, 0.0395009881422925, 0.05561264822134389, 0.12635869565217392, 0.04510753767292489, 0.029150197628458527, 0.04700716403162053, 0.06384387351778661, 0.3925351310352865, 0.009240207234540597, 0.10354592116820392, 0.06150252525252522, 0.04281620553359686, 0.14819664031620558, 0.05352041126512326, 0.06568675889328068, 0.01657608695652172, 0.19062757118657733, 0.03340909090909095, 0.07006916996047435, 0.011002964426877478, 0.09020850351339488, 0.04695369512307116, 0.05483973567193676, 0.24840415019762857, 0.056849061264822136, 0.025879446640316214, 0.12128318124749328, 0.18546566205533577, 0.06975516029863857]\n",
    "\n",
    "    35 OOB Scores : \n",
    "     [14.53287453337725, 15.017660928831349, 13.436488526570047, 14.107198686622214, 16.01733341809545, 12.601590858187995, 14.549772727272726, 10.7008998270751, 13.38334761883424, 15.176447724582784, 14.145968379446641, 15.950983750548968, 11.490838842672263, 13.140575440767572, 12.719290854307983, 12.930442509737203, 12.25596643256698, 13.8651185770751, 11.290968379446639, 13.484062796031196, 14.56314723320158, 11.327782855731224, 14.295874157912767, 15.249782632166097, 11.303486632630653, 14.666441178085197, 12.20390640452914, 13.143070423765382, 15.10691854001976, 13.172223274936549, 15.174440009826768, 15.2400395256917, 13.202148960835446, 14.20138666007905, 12.230044045129581]\n",
    "\n",
    "    95% CI of MSE :  [0.068, 0.122]\n",
    "\n",
    "    95% CI of OOB :  [13.124, 14.07]\n",
    " \n",
    "Task 3 Observations :\n",
    "\n",
    "    Price of the house for given Xq:  [18.5]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bootstrap_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
