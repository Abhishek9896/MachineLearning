{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HExLQrE4ZxR"
   },
   "source": [
    "<h1><font color='blue'> 8E and 8F: Finding the Probability P(Y==1|X)</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LuKrFzC4ZxV"
   },
   "source": [
    "<h2><font color='Geen'> 8E: Implementing Decision Function of SVM RBF Kernel</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wES-wWN4ZxX"
   },
   "source": [
    "<font face=' Comic Sans MS' size=3>After we train a kernel SVM model, we will be getting support vectors and their corresponsing coefficients $\\alpha_{i}$\n",
    "\n",
    "Check the documentation for better understanding of these attributes: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "<img src='https://i.imgur.com/K11msU4.png' width=500>\n",
    "\n",
    "As a part of this assignment you will be implementing the ```decision_function()``` of kernel SVM, here decision_function() means based on the value return by ```decision_function()``` model will classify the data point either as positive or negative\n",
    "\n",
    "Ex 1: In logistic regression After traning the models with the optimal weights $w$ we get, we will find the value $\\frac{1}{1+\\exp(-(wx+b))}$, if this value comes out to be < 0.5 we will mark it as negative class, else its positive class\n",
    "\n",
    "Ex 2: In Linear SVM After traning the models with the optimal weights $w$ we get, we will find the value of $sign(wx+b)$, if this value comes out to be -ve we will mark it as negative class, else its positive class.\n",
    "\n",
    "Similarly in Kernel SVM After traning the models with the coefficients $\\alpha_{i}$ we get, we will find the value of \n",
    "$sign(\\sum_{i=1}^{n}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here $K(x_{i},x_{q})$ is the RBF kernel. If this value comes out to be -ve we will mark $x_{q}$ as negative class, else its positive class.\n",
    "\n",
    "RBF kernel is defined as: $K(x_{i},x_{q})$ = $exp(-\\gamma ||x_{i} - x_{q}||^2)$\n",
    "\n",
    "For better understanding check this link: https://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z830CfMk4Zxa"
   },
   "source": [
    "## Task E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuBxHiCQ4Zxc"
   },
   "source": [
    "> 1. Split the data into $X_{train}$(60), $X_{cv}$(20), $X_{test}$(20)\n",
    "\n",
    "> 2. Train $SVC(gamma=0.001, C=100.)$ on the ($X_{train}$, $y_{train}$)\n",
    "\n",
    "> 3. Get the decision boundry values $f_{cv}$ on the $X_{cv}$ data  i.e. ` `$f_{cv}$ ```= decision_function(```$X_{cv}$```)```  <font color='red'>you need to implement this decision_function()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "fCgMNEvI4Zxf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ANUNIqCe4Zxn"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=5000, n_features=5, n_redundant=2,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHie1zqH4Zxt"
   },
   "source": [
    "### Pseudo code\n",
    "\n",
    "clf = SVC(gamma=0.001, C=100.)<br>\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "<font color='green'>def</font> <font color='blue'>decision_function</font>(Xcv, ...): #use appropriate parameters <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='green'>for</font> a data point $x_q$ <font color='green'>in</font> Xcv: <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='grey'>#write code to implement $(\\sum_{i=1}^{\\text{all the support vectors}}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here the values $y_i$, $\\alpha_{i}$, and $intercept$ can be obtained from the trained model</font><br>\n",
    "   <font color='green'>return</font> <font color='grey'><i># the decision_function output for all the data points in the Xcv</i></font>\n",
    "    \n",
    "fcv = decision_function(Xcv, ...)  <i># based on your requirement you can pass any other parameters </i>\n",
    "\n",
    "<b>Note</b>: Make sure the values you get as fcv, should be equal to outputs of clf.decision_function(Xcv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "h43kDT3M41u5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn's decision function :  [ 0.79925693 -0.83263201 -2.96299145 -3.33007061 -2.22950805]\n",
      "Custom Decision Function :  [ 0.79925693 -0.83263201 -2.96299145 -3.33007061 -2.22950805]\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma = 0.001 , C=100)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "sv = clf.support_vectors_\n",
    "intercept = clf.intercept_\n",
    "coef = clf.dual_coef_\n",
    "\n",
    "print(\"sklearn's decision function : \", clf.decision_function(X_cv)[:5])\n",
    "\n",
    "def decision_function(data):\n",
    "    lst = []\n",
    "    for xq in data:  \n",
    "        sum = 0\n",
    "        for i in range(len(sv)):\n",
    "            sum += (  ( coef[0][i]  *  (np.exp( -0.001 * (np.linalg.norm(sv[i]- xq))**2 ) ) ) )\n",
    "        lst.append(sum+intercept) #intercept to added after summation\n",
    "    flst = np.array(lst)\n",
    "    return flst\n",
    "\n",
    "\n",
    "fcv = decision_function(X_cv).flatten()\n",
    "print(\"Custom Decision Function : \",fcv[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0bKCboN4Zxu"
   },
   "source": [
    "<h2><font color='Geen'> 8F: Implementing Platt Scaling to find P(Y==1|X)</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMn7OEN94Zxw"
   },
   "source": [
    "Check this <a href='https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a'>PDF</a>\n",
    "<img src='https://i.imgur.com/CAMnVnh.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0n5EFkx4Zxz"
   },
   "source": [
    "## TASK F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0HOqVJq4Zx1"
   },
   "source": [
    "\n",
    "> 4. Apply SGD algorithm with ($f_{cv}$, $y_{cv}$) and find the weight $W$ intercept $b$ ```Note: here our data is of one dimensional so we will have a one dimensional weight vector i.e W.shape (1,)``` \n",
    "\n",
    "> Note1: Don't forget to change the values of $y_{cv}$ as mentioned in the above image. you will calculate y+, y- based on data points in train data\n",
    "\n",
    "> Note2: the Sklearn's SGD algorithm doesn't support the real valued outputs, you need to use the code that was done in the `'Logistic Regression with SGD and L2'` Assignment after modifying loss function, and use same parameters that used in that assignment.\n",
    "<img src='https://i.imgur.com/zKYE9Oc.png'>\n",
    "if Y[i] is 1, it will be replaced with y+ value else it will replaced with y- value\n",
    "\n",
    "> 5. For a given data point from $X_{test}$, $P(Y=1|X) = \\frac{1}{1+exp(-(W*f_{test}+ b))}$ where ` `$f_{test}$ ```= decision_function(```$X_{test}$```)```, W and b will be learned as metioned in the above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41918715 0.00047259 0.00047259 0.00047259 0.00047259]\n"
     ]
    }
   ],
   "source": [
    "N_p = 0\n",
    "N_n = 0\n",
    "y_p = 0\n",
    "y_n = 0\n",
    "\n",
    "for i in y_train:\n",
    "    if i==0:\n",
    "        N_n+=1\n",
    "    else:\n",
    "        N_p+=1\n",
    "        \n",
    "\n",
    "\n",
    "y_p = ((N_p+1)/(N_n+2))\n",
    "y_n = 1/(N_n+2)                 #calculating y_p , y_n using y_train\n",
    "\n",
    "y_cv_new = np.where(y_cv==0, y_n, y_p)     #replace values in y_cv with y_p and y_n\n",
    "\n",
    "print(y_cv_new[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 26.10it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def initialize_weights(dim):\n",
    "    w = np.zeros_like(dim)\n",
    "    b = 0 \n",
    "    return w,b\n",
    "\n",
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    sig = 1 /(1+ (np.exp(-1*z)))\n",
    "    return sig\n",
    "\n",
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    ln_arr = len(y_true)\n",
    "    loss = 0 \n",
    "    for i in range(ln_arr):\n",
    "        loss += (y_true[i] * np.log10(y_pred[i])) + ((1-y_true[i]) * np.log10(1-y_pred[i]))   \n",
    "    loss = (loss * -1)/ln_arr\n",
    "    return loss\n",
    "\n",
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "#     dw = []\n",
    "#     for i in range(len(x)):\n",
    "    f = (x *( y - sigmoid (np.dot(w.T,x) + b   )  ))   -  ((alpha *w)/N)\n",
    "#     dw.append(f)   \n",
    "    dw = np.array(f)\n",
    "    return dw\n",
    "\n",
    "def gradient_db(x,y,w,b):\n",
    "    '''In this function, we will compute gradient w.r.to b '''\n",
    "    db = y - sigmoid(np.dot(w.T,x) + b)\n",
    "            \n",
    "    return db\n",
    "\n",
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(0.99999)  #to avoid division by zero error\n",
    "        else:\n",
    "            predict.append(0.00001)  #to avoid division by zero error\n",
    "    return np.array(predict)\n",
    "\n",
    "def train(X_train,y_train,epochs,alpha,eta0):\n",
    "    dim=X_train[0] \n",
    "    w,b = initialize_weights(dim)\n",
    "    train_loss = [] #list of trainloss\n",
    "    \n",
    "    \n",
    "    e = []          #epoch number\n",
    "    for epoch in tqdm(range(epochs)):   #for every epoch\n",
    "        for x , y  in zip(X_train , y_train):    #for every point \n",
    "            gw = gradient_dw(x,y,w,b,alpha,len(X_train))    \n",
    "            gb = gradient_db(x,y,w,b)\n",
    "            w = w + (eta0*gw)\n",
    "            b = b + (eta0*gb)\n",
    "        train_loss.append(logloss(y_train ,pred(w,b, X_train)))\n",
    "        e.append(epoch+1)\n",
    "    return w,b,train_loss,e\n",
    "\n",
    "alpha=0.0001\n",
    "eta0=0.0001\n",
    "epochs=50\n",
    "\n",
    "w,b,train_loss ,e=train(fcv, y_cv_new , epochs , alpha , eta0)\n",
    "\n",
    "plt.plot(e, train_loss, label='Train loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"LogLoss\")\n",
    "plt.title(\"Loss Vs Epochs\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P==1|X (for every pointin Xtest):  [[0.03165015]\n",
      " [0.17257785]\n",
      " [0.33546007]\n",
      " [0.51510381]\n",
      " [0.45572534]]\n"
     ]
    }
   ],
   "source": [
    "df_xtest = decision_function(X_test)\n",
    "\n",
    "for i in X_test:\n",
    "    xx = 1/( 1 + np.exp( -1*(  (w * df_xtest)+b  )  )  )\n",
    "    \n",
    "print(\"P==1|X (for every pointin Xtest): \",xx[:5])  #printing first five points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTY7z2bd4Zx2"
   },
   "source": [
    "__Note: in the above algorithm, the steps 2, 4 might need hyper parameter tuning, To reduce the complexity of the assignment we are excluding the hyerparameter tuning part, but intrested students can try that__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CM3odN1Z4Zx3"
   },
   "source": [
    "\n",
    "If any one wants to try other calibration algorithm istonic regression also please check these tutorials\n",
    "\n",
    "1. http://fa.bianp.net/blog/tag/scikit-learn.html#fn:1\n",
    "\n",
    "2. https://drive.google.com/open?id=1MzmA7QaP58RDzocB0RBmRiWfl7Co_VJ7\n",
    "\n",
    "3. https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a\n",
    "\n",
    "4. https://stat.fandom.com/wiki/Isotonic_regression#Pool_Adjacent_Violators_Algorithm\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "8E&F_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
